# SCOTUS AI Encoding Configuration
# ===============================
# Centralized hyperparameters for biography and case description encoding

# Model Configuration
# -------------------
BIO_MODEL_NAME=sentence-transformers/all-roberta-large-v1
DESCRIPTION_MODEL_NAME=sentence-transformers/all-roberta-large-v1

# Embedding Configuration
# -----------------------
EMBEDDING_DIM=384
MAX_SEQUENCE_LENGTH=512

# Batch Processing
# ---------------
BIO_BATCH_SIZE=16
DESCRIPTION_BATCH_SIZE=8

# Device Configuration
# -------------------
# Options: cuda, cpu, auto (auto will detect available device)
DEVICE=auto

# Output Paths
# -----------
BIO_OUTPUT_FILE=data/processed/encoded_bios.pkl
DESCRIPTION_OUTPUT_FILE=data/processed/encoded_descriptions.pkl
DATASET_FILE=data/processed/case_dataset.json
PRETRAINING_TRUNC_BIO_FILE=data/processed/encoded_pre_trunc_bios.pkl
PRETRAINING_FULL_BIO_FILE=data/processed/encoded_pre_full_bios.pkl
PRETRAINING_DATASET_FILE=data/processed/pretraining_dataset.json

# Input Paths
# -----------
BIO_INPUT_DIR=data/processed/bios
DESCRIPTION_INPUT_DIR=data/processed/case_descriptions
PRETRAINING_TRUNC_BIO_DIR=data/processed/bios/
PRETRAINING_FULL_BIO_DIR=data/raw/bios/

# Processing Limits
# -----------------
# Maximum word count for case descriptions (larger files will be skipped)
MAX_DESCRIPTION_WORDS=10000

# Progress and Logging
# -------------------
# Whether to show detailed progress bars
SHOW_PROGRESS=true

# Memory Management
# ----------------
# Whether to clear GPU cache on memory errors
CLEAR_CACHE_ON_OOM=true

# Model Loading
# ------------
# Whether to use local cache for models
USE_MODEL_CACHE=true

# Advanced Settings
# ----------------
# Temperature for any sampling operations
TEMPERATURE=1.0

# Random seed for reproducibility
RANDOM_SEED=42

# Number of CPU threads for data loading
NUM_WORKERS=4 