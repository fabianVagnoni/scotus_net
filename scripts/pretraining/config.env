# Contrastive Justice Pretraining Configuration
# ===========================================
# Configuration file for contrastive learning of justice biography encoders

# Model Configuration
# -------------------
MODEL_NAME=sentence-transformers/all-roberta-large-v1
DROPOUT_RATE=0.4
USE_NOISE_REG=true
NOISE_REG_ALPHA=5.0

# Training Configuration
# ----------------------
BATCH_SIZE=4
LEARNING_RATE=4e-05
NUM_EPOCHS=25
WEIGHT_DECAY=0.007
NUM_WORKERS=2

# Loss Configuration
# ------------------
TEMPERATURE=0.015
ALPHA=0.8

# Learning Rate Scheduler
# -----------------------
LR_SCHEDULER_FACTOR=0.5
LR_SCHEDULER_PATIENCE=10
MAX_PATIENCE=15

# Data Configuration
# ------------------
VAL_SPLIT=0.2
JUSTICES_FILE=data/raw/justices.json
TRUNC_BIO_TOKENIZED_FILE=data/processed/encoded_pre_trunc_bios.pkl
FULL_BIO_TOKENIZED_FILE=data/processed/encoded_pre_full_bios.pkl
PRETRAINING_DATASET_FILE=data/processed/pretraining_dataset.json
TEST_SET_SIZE=20
VAL_SET_SIZE=20

# Output Configuration
# --------------------
MODEL_OUTPUT_DIR=models/contrastive_justice 

--------------------------------------------

# =============================================================================
# HYPERPARAMETER OPTIMIZATION CONFIGURATION
# =============================================================================

# Study Configuration
# -------------------
# Number of optimization trials to run
OPTUNA_N_TRIALS=50
# Maximum time per trial in seconds (0 for no limit)
OPTUNA_MAX_TRIAL_TIME=1500
# Maximum epochs per trial during optimization
OPTUNA_MAX_EPOCHS=5
# Minimum epochs before early stopping can occur
OPTUNA_MIN_EPOCHS=2
# Early stopping patience for optimization trials
OPTUNA_EARLY_STOP_PATIENCE=2
# Optuna pruner startup trials
OPTUNA_PRUNER_STARTUP_TRIALS=5
# Optuna pruner warmup steps
OPTUNA_PRUNER_WARMUP_STEPS=2

# Hyperparameter Tuning Control
# -----------------------------
# Controls which hyperparameters to optimize during hyperparameter tuning.
# Set to 'true' to allow Optuna to suggest values for the parameter.
# Set to 'false' to use the default value defined above in this config file.

# Training Parameters Control
TUNE_BATCH_SIZE=false
TUNE_LEARNING_RATE=false
TUNE_WEIGHT_DECAY=false
TUNE_DROPOUT_RATE=true
TUNE_NOISE_REG_ALPHA=true

# Loss Parameters Control
TUNE_TEMPERATURE=false
TUNE_ALPHA=false

# Hyperparameter Search Spaces
# ----------------------------
# Batch size options (comma-separated)
OPTUNA_BATCH_SIZE_OPTIONS=2,4,8
# Learning rate range (min,max,log_scale)
OPTUNA_LEARNING_RATE_RANGE=1e-6,1e-4,true
# Weight decay range (min,max,log_scale)
OPTUNA_WEIGHT_DECAY_RANGE=1e-5,1e-2,true
# Dropout rate range (min,max,step)
OPTUNA_DROPOUT_RATE_RANGE=0.0,0.7,0.1
# Temperature range (min,max,log_scale)
OPTUNA_TEMPERATURE_RANGE=0.01,1.0,true
# Alpha range (min,max,step)
OPTUNA_ALPHA_RANGE=0.0,1.0,0.1
# NEFTune noise regularization scale (alpha)
OPTUNA_NOISE_REG_ALPHA_RANGE=0.1,10.0,true

# Time-Based Cross-Validation (CVTT)
# ----------------------------------
# Enable CV-through-time for pretraining hyperparameter tuning
USE_TIME_BASED_CV=true
# Number of folds (validation windows)
TIME_BASED_CV_FOLDS=3
# Number of justices in each training window
TIME_BASED_CV_TRAIN_SIZE=60
# Number of justices in each validation window
TIME_BASED_CV_VAL_SIZE=20