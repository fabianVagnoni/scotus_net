# Contrastive Justice Pretraining Configuration
# ===========================================
# Configuration file for contrastive learning of justice biography encoders

# Model Configuration
# -------------------
MODEL_NAME=sentence-transformers/all-roberta-large-v1
DROPOUT_RATE=0.3

# Training Configuration
# ----------------------
BATCH_SIZE=4
LEARNING_RATE=5.0302305787079035e-05
NUM_EPOCHS=69
WEIGHT_DECAY=1.2040540520282e-05
NUM_WORKERS=2

# Loss Configuration
# ------------------
TEMPERATURE=0.01124933596622745
ALPHA=0.7

# Learning Rate Scheduler
# -----------------------
LR_SCHEDULER_FACTOR=0.5
LR_SCHEDULER_PATIENCE=10
MAX_PATIENCE=15

# Data Configuration
# ------------------
VAL_SPLIT=0.2
JUSTICES_FILE=data/raw/justices.json
TRUNC_BIO_TOKENIZED_FILE=data/processed/encoded_pre_trunc_bios.pkl
FULL_BIO_TOKENIZED_FILE=data/processed/encoded_pre_full_bios.pkl
PRETRAINING_DATASET_FILE=data/processed/pretraining_dataset.json
TEST_SET_SIZE=20
VAL_SET_SIZE=20

# Output Configuration
# --------------------
MODEL_OUTPUT_DIR=models/contrastive_justice 

--------------------------------------------

# =============================================================================
# HYPERPARAMETER OPTIMIZATION CONFIGURATION
# =============================================================================

# Study Configuration
# -------------------
# Number of optimization trials to run
OPTUNA_N_TRIALS=5
# Maximum time per trial in seconds (0 for no limit)
OPTUNA_MAX_TRIAL_TIME=600
# Maximum epochs per trial during optimization
OPTUNA_MAX_EPOCHS=5
# Minimum epochs before early stopping can occur
OPTUNA_MIN_EPOCHS=2
# Early stopping patience for optimization trials
OPTUNA_EARLY_STOP_PATIENCE=2
# Optuna pruner startup trials
OPTUNA_PRUNER_STARTUP_TRIALS=5
# Optuna pruner warmup steps
OPTUNA_PRUNER_WARMUP_STEPS=2

# Hyperparameter Tuning Control
# -----------------------------
# Controls which hyperparameters to optimize during hyperparameter tuning.
# Set to 'true' to allow Optuna to suggest values for the parameter.
# Set to 'false' to use the default value defined above in this config file.

# Training Parameters Control
TUNE_BATCH_SIZE=true
TUNE_LEARNING_RATE=true
TUNE_WEIGHT_DECAY=true
TUNE_DROPOUT_RATE=true

# Loss Parameters Control
TUNE_TEMPERATURE=true
TUNE_ALPHA=true

# Hyperparameter Search Spaces
# ----------------------------
# Batch size options (comma-separated)
OPTUNA_BATCH_SIZE_OPTIONS=2,4,8
# Learning rate range (min,max,log_scale)
OPTUNA_LEARNING_RATE_RANGE=1e-6,1e-4,true
# Weight decay range (min,max,log_scale)
OPTUNA_WEIGHT_DECAY_RANGE=1e-5,1e-2,true
# Dropout rate range (min,max,step)
OPTUNA_DROPOUT_RATE_RANGE=0.0,0.5,0.1
# Temperature range (min,max,log_scale)
OPTUNA_TEMPERATURE_RANGE=0.01,1.0,true
# Alpha range (min,max,step)
OPTUNA_ALPHA_RANGE=0.0,1.0,0.1